# Nama : Meinisa
# NIM : 121450076
# Kelas : RB

# TUGAS ABD RB - Three Ways of Storing and Accessing Lots of Images in Python

# Setup
## A Dataset to Play With
Dataset CIFAR-10 terdiri dari 60.000 gambar berwarna dengan resolusi 32x32 piksel yang dikelompokkan ke dalam sepuluh kelas objek berbeda seperti anjing, kucing, dan pesawat. Dataset ini adalah bagian dari kumpulan data yang lebih besar, yaitu TinyImages. Untuk menggunakan dataset ini, Anda dapat mengunduhnya dalam versi Python melalui tautan yang disediakan di artikel. Perlu diingat bahwa dataset ini akan membutuhkan sekitar 163MB ruang disk. Setelah diunduh dan diekstrak, Anda akan menemukan bahwa file-file dalam dataset tidak dalam format gambar yang dapat langsung dibaca oleh manusia. File-file tersebut telah diserialisasi dan disimpan dalam batch menggunakan cPickle. Untuk memuat dataset ke dalam array NumPy, Anda dapat menggunakan kode Python untuk mengurai ("unpickle") masing-masing dari lima file batch dan memuat semua gambar ke dalam array NumPy. Meskipun artikel tersebut tidak membahas secara mendalam tentang penggunaan modul pickle atau cPickle, penting untuk diketahui bahwa modul ini memungkinkan serialisasi objek Python apa pun tanpa kode tambahan.

## Setup for Storing Images on Disk
  ```
  pip install pillow
  ```
![alt text](image-1.png)

## Getting Started With LMDB
  ```
  pip install lmdb
  ```
![alt text](image-2.png)

## Getting Started With HDF5
  ```
  pip install h5py
  ```
![alt text](image-3.png)

# Storing a Single Image
**Membuat Direktori untuk Setiap Metode Penyimpanan**:  
   ```bash
   mkdir data/disk
   mkdir data/lmdb
   mkdir data/hdf5
   ```
**Menyimpan Jalur Direktori ke dalam Variabel Python**:
```python
from pathlib import Path
disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```
Jika menggunakan dataset CIFAR-10 yang terdiri dari 50,000 gambar, gunakan setiap gambar dua kali untuk mendapatkan total 100,000 gambar dalam eksperimen. Bandingkan kinerja metode penyimpanan dengan menguji berbagai jumlah gambar, mulai dari satu gambar hingga 100,000 gambar.

## Storing to Disk
**Simpan Gambar ke Disk**
```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```

**Simpan Meta Data**
Ada beberapa pendekatan yang dapat dipertimbangkan untuk menyimpan informasi meta data, seperti label, yang terkait dengan gambar. Salah satu metode adalah dengan menyematkan label ke dalam nama file gambar itu sendiri. Pendekatan ini menghindari kebutuhan untuk membuat file tambahan, tetapi dapat membuat pengelolaan file menjadi lebih rumit. Metode alternatif adalah menyimpan label dalam file terpisah. Anda dapat membuat file dengan format `.csv` (Comma-Separated Values) untuk menyimpan label. Pendekatan ini memungkinkan Anda untuk mengelola label tanpa perlu memuat seluruh gambar, yang dapat lebih efisien dalam hal penggunaan sumber daya.

## Storing to LMDB
**LMDB (Lightning Memory-Mapped Database)** adalah sistem penyimpanan data berbentuk kunci-nilai di mana setiap entri data disimpan sebagai array byte. Dalam LMDB, kunci berfungsi sebagai pengenal unik untuk setiap gambar yang disimpan dalam database, sementara nilai merupakan data gambar itu sendiri. Baik kunci maupun nilai harus berupa string dalam LMDB. Oleh karena itu, data gambar (nilai) biasanya diserialisasi menjadi format string sebelum disimpan dalam database. Saat data gambar dibaca kembali dari database, proses deserialisasi dilakukan untuk mengonversi data string menjadi format aslinya (misalnya, array NumPy atau objek gambar). Dengan demikian, LMDB menyediakan penyimpanan data yang efisien dalam bentuk pasangan kunci-nilai, di mana kunci berfungsi sebagai pengenal unik untuk setiap gambar, dan nilai adalah data gambar yang telah diserialisasi menjadi format string.

**Gunakan modul `pickle` untuk melakukan serialisasi**. Modul `pickle` di Python digunakan untuk melakukan serialisasi objek Python ke dalam format byte yang dapat disimpan atau dikirimkan. Dengan menggunakan `pickle`, Anda dapat menyerialisasi data gambar dan informasi meta data terkait ke dalam format yang dapat disimpan dalam basis data. Selain menyimpan data gambar itu sendiri, Anda juga dapat menyertakan informasi meta data yang terkait dengan gambar tersebut dalam basis data yang sama. Dengan menyimpan meta data bersama dengan data gambar, Anda tidak perlu melakukan proses penghubungan (mapping) antara data gambar dan meta data saat memuat dataset dari disk. Dengan menyimpan meta data gambar bersama dengan data gambar itu sendiri dalam basis data, Anda dapat menghindari kerumitan dalam menghubungkan kembali (re-mapping) meta data dengan data gambar saat memuat dataset dari disk. Ini dapat menyederhanakan proses pemuatan data dan menjaga integritas antara data gambar dan informasi meta data terkait. Dengan demikian, penggunaan modul `pickle` untuk serialisasi dan penyimpanan meta data gambar bersama dengan data gambar dalam basis data dapat mempermudah pengelolaan dan pemuatan dataset secara keseluruhan.

**Membuat Kelas Python untuk Gambar dan Meta Data**
```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```
**Menetapkan Ukuran Peta**
Menentukan jumlah memori yang akan digunakan oleh LMDB (Lightning Memory-Mapped Database) adalah langkah penting karena LMDB menggunakan teknik memori-mapped untuk pengelolaan data. Untuk memastikan LMDB dapat mengalokasikan dan mengelola memori secara efisien, perlu dilakukan estimasi jumlah memori yang akan digunakan oleh database. Variabel yang digunakan untuk mengatur jumlah memori ini adalah `map_size`. Variabel `map_size` menentukan ukuran maksimum dari ruang alamat memori yang akan dimapping untuk database LMDB. Dengan menetapkan `map_size`, Anda mengatur batas atas memori yang dapat digunakan oleh LMDB untuk menyimpan data. Ini membantu dalam menghindari alokasi memori yang tidak efisien dan memastikan bahwa database dapat mengelola data dengan performa yang optimal. Sebelum menggunakan LMDB, langkah pertama adalah mengestimasi jumlah memori yang dibutuhkan untuk menyimpan seluruh data yang akan dimasukkan ke dalam database. Estimasi ini kemudian digunakan untuk mengatur variabel `map_size` sesuai dengan kebutuhan. Dengan demikian, LMDB dapat mengalokasikan memori secara optimal, menghindari kehabisan memori, dan memastikan bahwa database dapat beroperasi dengan performa terbaik.

**Operasi Transaksi**
```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```


## Storing With HDF5
Memahami dan mengelola penyimpanan data menggunakan file HDF5 melibatkan beberapa langkah penting. File HDF5 dapat menyimpan lebih dari satu dataset, yang memungkinkan penyimpanan berbagai jenis data secara efisien. Dalam konteks penyimpanan gambar dan meta data terkait, Anda perlu membuat dua dataset terpisah dalam satu file HDF5: satu untuk gambar dan satu lagi untuk meta data gambar. Untuk menentukan tipe data yang akan disimpan dalam dataset, gunakan `h5py.h5t.STD_U8BE`. Tipe data ini adalah integer 8-bit tak bertanda yang sangat cocok untuk menyimpan nilai pixel gambar, karena nilai pixel biasanya berkisar antara 0 hingga 255. Memilih tipe data yang sesuai sangat penting karena tipe data yang dipilih mempengaruhi kebutuhan runtime dan penyimpanan dari file HDF5. Tipe data yang lebih efisien akan mengoptimalkan penggunaan sumber daya. Dengan memilih tipe data yang tepat, Anda memastikan bahwa file HDF5 dapat mengelola data gambar dan meta data secara efisien, baik dari segi penggunaan memori maupun kinerja runtime. Pastikan tipe data yang dipilih memenuhi kebutuhan minimal Anda untuk memaksimalkan efisiensi penyimpanan dan pemrosesan data.

```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

## Experiments for Storing a Single Image
**Menyiapkan Fungsi Penyimpanan**
```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```

**Melakukan Eksperimen Waktu**
```python
from timeit import timeit
store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
**Hasil Eksperimen**
![alt text](image-4.png)

# Storing Many Images
## Adjusting the Code for Many Images
```python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```
## Preparing the Dataset 
```python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```
## Experiment for Storing Many Images
```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```
Perlu bersabar sejenak dan menunggu dengan penuh penasaran sementara 111,110 gambar disimpan tiga kali masing-masing ke disk Anda, dalam tiga format yang berbeda. Anda juga perlu bersiap untuk mengucapkan selamat tinggal pada sekitar 2 GB ruang disk.

Grafik pertama menunjukkan waktu penyimpanan normal, tanpa penyesuaian, menyoroti perbedaan drastis antara menyimpan ke file .png dan ke LMDB atau HDF5.
![alt text](image-5.png)
Grafik kedua menunjukkan log dari waktu yang diukur, menyoroti bahwa HDF5 mulai lebih lambat dari LMDB tetapi, dengan jumlah gambar yang lebih besar, akhirnya sedikit lebih unggul.
![alt text](image-6.png)


# Reading a Single Image
## Reading From Disk
```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```
## Reading From LMDB
```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

## Reading From HDF5
```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label

_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

## Experiment for Reading a Single Image
```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
**Hasil Eksperimen**
![alt text](image-7.png)

## Kesimpulan
Membaca file .png (gambar) dan .csv (metadata) secara langsung dari disk sedikit lebih cepat dibandingkan dengan menggunakan metode penyimpanan lainnya seperti LMDB atau HDF5. Kecepatan ini diperoleh karena pembacaan file langsung dari sistem file disk umumnya merupakan operasi yang cukup cepat. Meskipun pembacaan file .png dan .csv dari disk sedikit lebih cepat, ketiga metode penyimpanan (disk, LMDB, dan HDF5) secara keseluruhan memberikan performa yang cepat dan hampir sama. Perbedaan kecepatan antara ketiga metode ini dianggap tidak signifikan atau tidak terlalu besar. Dengan demikian, meskipun pembacaan file gambar dan metadata secara langsung dari disk sedikit lebih cepat, semua metode penyimpanan (disk, LMDB, dan HDF5) memberikan performa yang cepat dan hampir setara. Perbedaan kecepatan yang kecil tersebut tidak dianggap sebagai faktor yang sangat signifikan dalam memilih metode penyimpanan yang akan digunakan.

Dari analisis kedua grafik, metode HDF5 menunjukkan peningkatan performa yang signifikan seiring dengan peningkatan jumlah gambar, meskipun awalnya lebih lambat dibandingkan metode lain. Hal ini menunjukkan bahwa HDF5 mungkin lebih efisien dalam skenario pembacaan batch gambar yang lebih besar. Grafik logaritma waktu baca menggarisbawahi bahwa dengan jumlah gambar yang sedikit, perbedaan antara metode penyimpanan tidak terlihat sejelas saat menggunakan jumlah gambar yang lebih banyak.
